{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU Google BERT Sentence Classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Fi64WIX-QpmG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google authentication"
      ]
    },
    {
      "metadata": {
        "id": "GTnKeCW3CF4J",
        "colab_type": "code",
        "outputId": "028d6f43-b94a-4830-ee32-16a2a088e046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "use_tpu = 'COLAB_TPU_ADDR' in os.environ\n",
        "if use_tpu:\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print('TPU address is', TPU_ADDRESS)\n",
        "  \n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    # Now credentials are set for all future sessions on this TPU.\n",
        "else:\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.77.70.18:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VnhRZzpNQfiA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download *improv* project"
      ]
    },
    {
      "metadata": {
        "id": "dgNbGwQ6CxV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "049c4ba1-d816-4969-c1b1-c8b2ff9d636e"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!test -d improv || git clone https://github.com/rikhuijzer/improv improv\n",
        "if not 'improv' in sys.path:\n",
        "  sys.path += ['improv']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'improv'...\n",
            "remote: Enumerating objects: 368, done.\u001b[K\n",
            "remote: Counting objects: 100% (368/368), done.\u001b[K\n",
            "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
            "remote: Total 368 (delta 223), reused 270 (delta 129), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (368/368), 2.22 MiB | 10.21 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g461dLKoP937",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BERT pre-trained \n"
      ]
    },
    {
      "metadata": {
        "id": "y6M6oWJdP-F7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bucket = 'benchmark-tpu-bucket' #@param {type:\"string\"}\n",
        "assert bucket, 'Must specify an existing GCS bucket name'\n",
        "bucket_models_dir = 'gs://{}/bert/models'.format(bucket)\n",
        "bert_model = 'BERT-Large, Uncased' #@param ['BERT-Base, Uncased', 'BERT-Large, Uncased']\n",
        "bert_model_map = {\n",
        "    'BERT-Base, Uncased': 'uncased_L-12_H-768_A-12',\n",
        "    'BERT-Large, Uncased': 'uncased_L-24_H-1024_A-16',\n",
        "}\n",
        "bert_model_mapped = bert_model_map[bert_model]\n",
        "\n",
        "bert_pretrained_dir = 'gs://cloud-tpu-checkpoints/bert/' + bert_model_mapped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R7lV_v1GEmEf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define params"
      ]
    },
    {
      "metadata": {
        "id": "_z8ofkonDcyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from src.config import HParams\n",
        "from src.utils import get_project_root\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "task_name = 'askubuntu'\n",
        "epochs = 1  #@param {type:\"integer\"}\n",
        "output_dir_name = str(datetime.now() + timedelta(hours=1))[:-7]\n",
        "tpu_name = 'grpc://' + os.environ['COLAB_TPU_ADDR'] if use_tpu else ''\n",
        "\n",
        "hparams = HParams(\n",
        "  data_dir=get_project_root() / 'data' / task_name,\n",
        "  bert_config_file=os.path.join(bert_pretrained_dir, 'bert_config.json'),\n",
        "  task_name=task_name,\n",
        "  vocab_file=os.path.join(bert_pretrained_dir, 'vocab.txt'),\n",
        "  output_dir=bucket_models_dir + '/{}/{}'.format(task_name, output_dir_name),\n",
        "  init_checkpoint=os.path.join(bert_pretrained_dir, 'bert_model.ckpt'),\n",
        "  do_lower_case=bert_model.startswith('uncased'),\n",
        "  max_seq_length=128,\n",
        "  do_train_eval=False,\n",
        "  do_train=True,\n",
        "  do_eval=False,\n",
        "  do_predict=False, \n",
        "  train_batch_size=32,\n",
        "  eval_batch_size=8,\n",
        "  predict_batch_size=8,\n",
        "  learning_rate=5e-5,\n",
        "  num_train_epochs=epochs,\n",
        "  warmup_proportion=0.1,\n",
        "  save_checkpoints_steps=1000,\n",
        "  iterations_per_loop=-1,  # updated below \n",
        "  use_tpu=use_tpu,\n",
        "  tpu_name=tpu_name,\n",
        "  tpu_zone=None,\n",
        "  gcp_project=None,\n",
        "  master=None,\n",
        "  num_tpu_cores=8\n",
        ")\n",
        "\n",
        "tf.gfile.MakeDirs(hparams.output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oe0WrC7OoeGd",
        "colab_type": "code",
        "outputId": "818d6837-5a1b-420e-b536-38d68ef88f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1666
        }
      },
      "cell_type": "code",
      "source": [
        "# update iterations per loop\n",
        "!pip install rasa_nlu==0.13.8\n",
        "from src.my_estimator import get_examples, SetType\n",
        "\n",
        "data_filename = hparams.data_dir / (hparams.task_name + '.tsv')\n",
        "train_examples = get_examples(data_filename, SetType.train)\n",
        "n_train = len(train_examples)\n",
        "batches_per_epoch = float(n_train) / float(hparams.train_batch_size)\n",
        "iterations_per_loop = int(10 * batches_per_epoch)\n",
        "hparams = hparams._replace(iterations_per_loop=iterations_per_loop)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rasa_nlu==0.13.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/d2/2e6a081f3d222df01a3d941d7029e52c20619d53d557e721f096962d7293/rasa_nlu-0.13.8-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 4.9MB/s \n",
            "\u001b[?25hCollecting pathlib (from rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (2.18.4)\n",
            "Collecting packaging (from rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/89/d1/92e6df2e503a69df9faab187c684585f0136662c12bb1f36901d426f3fab/packaging-18.0-py2.py3-none-any.whl\n",
            "Collecting gevent (from rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/e5/8bbad57fa8a565e04c696e3413d4051cc3cbb40d04c5d6ad9808ba991d5c/gevent-1.3.7-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.5MB 5.5MB/s \n",
            "\u001b[?25hCollecting simplejson (from rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/24/c35fb1c1c315fc0fffe61ea00d3f88e85469004713dab488dee4f35b0aff/simplejson-3.16.0.tar.gz (81kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 22.8MB/s \n",
            "\u001b[?25hCollecting klein (from rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/6b/adc97a7bb3fb781fdd9e49177ad873c1479f87b9745271cbeda81cbb9cc8/klein-17.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (4.28.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (3.6.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (0.16.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (2.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (3.13)\n",
            "Requirement already satisfied: matplotlib~=2.0 in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (2.1.2)\n",
            "Collecting coloredlogs (from rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/0f/7877fc42fff0b9d70b6442df62d53b3868d3a6ad1b876bdb54335b30ff23/coloredlogs-10.0-py2.py3-none-any.whl (47kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from rasa_nlu==0.13.8) (1.14.6)\n",
            "Collecting cloudpickle (from rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/87/7b7ef3038b4783911e3fdecb5c566e3a817ce3e890e164fc174c088edb1e/cloudpickle-0.6.1-py2.py3-none-any.whl\n",
            "Collecting boto3 (from rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/5e/d39501836d6b3a198fc8ca34ca058f82f555c0e48b7a929f972cfc066e99/boto3-1.9.53-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 29.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->rasa_nlu==0.13.8) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->rasa_nlu==0.13.8) (2018.10.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->rasa_nlu==0.13.8) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->rasa_nlu==0.13.8) (2.6)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->rasa_nlu==0.13.8) (2.3.0)\n",
            "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\" (from gevent->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 18.8MB/s \n",
            "\u001b[?25hCollecting Twisted>=15.5 (from klein->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/0e/a72d85a55761c2c3ff1cb968143a2fd5f360220779ed90e0fadf4106d4f2/Twisted-18.9.0.tar.bz2 (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 8.9MB/s \n",
            "\u001b[?25hCollecting incremental (from klein->rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.6/dist-packages (from klein->rasa_nlu==0.13.8) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=2.0->rasa_nlu==0.13.8) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib~=2.0->rasa_nlu==0.13.8) (2018.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=2.0->rasa_nlu==0.13.8) (0.10.0)\n",
            "Collecting humanfriendly>=4.7 (from coloredlogs->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/1e/13d96248e3fcaa7777b61fa889feab44865c85e524bbd667acfa0d8b66e3/humanfriendly-4.17-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 25.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.13.0,>=1.12.53 (from boto3->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/f6/1b481cef9ad9978b8c8e57713416af5b041d7742912087188fc46a638480/botocore-1.12.53-py2.py3-none-any.whl (5.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.0MB 6.6MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.9MB/s \n",
            "\u001b[?25hCollecting zope.interface>=4.4.2 (from Twisted>=15.5->klein->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/17/1d198a6aaa9aa4590862fe3d3a2ed7dd808050cab4eebe8a2f2f813c1376/zope.interface-4.6.0-cp36-cp36m-manylinux1_x86_64.whl (167kB)\n",
            "\u001b[K    100% |████████████████████████████████| 174kB 31.2MB/s \n",
            "\u001b[?25hCollecting constantly>=15.1 (from Twisted>=15.5->klein->rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
            "Collecting Automat>=0.3.0 (from Twisted>=15.5->klein->rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/86/14c16bb98a5a3542ed8fed5d74fb064a902de3bdd98d6584b34553353c45/Automat-0.7.0-py2.py3-none-any.whl\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=15.5->klein->rasa_nlu==0.13.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/b6/84d0c863ff81e8e7de87cff3bd8fd8f1054c227ce09af1b679a8b17a9274/hyperlink-18.0.0-py2.py3-none-any.whl\n",
            "Collecting PyHamcrest>=1.9.0 (from Twisted>=15.5->klein->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d5/d37fd731b7d0e91afcc84577edeccf4638b4f9b82f5ffe2f8b62e2ddc609/PyHamcrest-1.9.0-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from Twisted>=15.5->klein->rasa_nlu==0.13.8) (18.2.0)\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.53->boto3->rasa_nlu==0.13.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zope.interface>=4.4.2->Twisted>=15.5->klein->rasa_nlu==0.13.8) (40.6.2)\n",
            "Building wheels for collected packages: pathlib, simplejson, Twisted\n",
            "  Running setup.py bdist_wheel for pathlib ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f9/b2/4a/68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
            "  Running setup.py bdist_wheel for simplejson ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5d/1a/1e/0350bb3df3e74215cd91325344cc86c2c691f5306eb4d22c77\n",
            "  Running setup.py bdist_wheel for Twisted ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/57/2e/89/11ba83bc08ac30a5e3a6005f0310c78d231b96a270def88ca0\n",
            "Successfully built pathlib simplejson Twisted\n",
            "Installing collected packages: pathlib, packaging, greenlet, gevent, simplejson, zope.interface, constantly, incremental, Automat, hyperlink, PyHamcrest, Twisted, klein, humanfriendly, coloredlogs, cloudpickle, jmespath, docutils, botocore, s3transfer, boto3, rasa-nlu\n",
            "Successfully installed Automat-0.7.0 PyHamcrest-1.9.0 Twisted-18.9.0 boto3-1.9.53 botocore-1.12.53 cloudpickle-0.6.1 coloredlogs-10.0 constantly-15.1.0 docutils-0.14 gevent-1.3.7 greenlet-0.4.15 humanfriendly-4.17 hyperlink-18.0.0 incremental-17.5.0 jmespath-0.9.3 klein-17.10.0 packaging-18.0 pathlib-1.0.1 rasa-nlu-0.13.8 s3transfer-0.1.13 simplejson-3.16.0 zope.interface-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JTIT6dVxEpmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Last preparations"
      ]
    },
    {
      "metadata": {
        "id": "DDsZQVrGEoNg",
        "colab_type": "code",
        "outputId": "11d72ef1-eb58-4af8-8fd9-6ca6a41f48b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "'''\n",
        "from src.config import get_debug_hparams\n",
        "from src.my_classifier import (\n",
        "    get_model_fn_and_estimator, evaluate, train, train_eval, predict\n",
        ")\n",
        "\n",
        "model_fn, estimator = get_model_fn_and_estimator(hparams)\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom src.config import get_debug_hparams\\nfrom src.my_classifier import (\\n    get_model_fn_and_estimator, evaluate, train, train_eval, predict\\n)\\n\\nmodel_fn, estimator = get_model_fn_and_estimator(hparams)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "EVySCfr0w6Rs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## New train eval loop"
      ]
    },
    {
      "metadata": {
        "id": "EtiQR2XEw9iw",
        "colab_type": "code",
        "outputId": "12c01422-ef81-4ea0-aba8-2ddd6ad6b9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3259
        }
      },
      "cell_type": "code",
      "source": [
        "from src.my_estimator import train_and_evaluate\n",
        "\n",
        "train_and_evaluate(hparams)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:train_batch_size=32  eval_batch_size=8  max_steps=1\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f00a49f41e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://benchmark-tpu-bucket/bert/models/askubuntu/2018-11-28 10:34:59', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.77.70.18:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f00a40f6940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.77.70.18:8470', '_evaluation_master': b'grpc://10.77.70.18:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7f00b92681d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Writing example 0 of 53\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-0\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] to record my screen ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2000 2501 2026 3898 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: None (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] can [UNK] highlight or ann ##ota ##te [UNK] ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2064 100 12944 2030 5754 17287 2618 100 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: None (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-2\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] it worth upgrading from 12 . 04 [UNK] to 13 . 04 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2009 4276 25925 2013 2260 1012 5840 100 2000 2410 1012 5840 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Make Update (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-3\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] to 12 . 04 64 bit [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2000 2260 1012 5840 4185 2978 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Make Update (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-4\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] to upgrade [UNK] 14 . 04 . 1 to 14 . 04 . 2 ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2000 12200 100 2403 1012 5840 1012 1015 2000 2403 1012 5840 1012 1016 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Make Update (id = 0)\n",
            "INFO:tensorflow:  Num steps = 1\n",
            "WARNING:tensorflow:There currently is no difference between dev and test set.\n",
            "INFO:tensorflow:Writing example 0 of 109\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-0\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] software can [UNK] use to view ep ##ub documents ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 4007 2064 100 2224 2000 3193 4958 12083 5491 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Software Recommendation (id = 4)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-1\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] [UNK] [UNK] would you recommend ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 100 100 2052 2017 16755 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Software Recommendation (id = 4)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-2\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] [UNK] are available for [UNK] ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 100 2024 2800 2005 100 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Software Recommendation (id = 4)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-3\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] ' s the best [UNK] [UNK] [UNK] ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 1005 1055 1996 2190 100 100 100 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Software Recommendation (id = 4)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-4\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] to read a [UNK] code ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2000 3191 1037 100 3642 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: Software Recommendation (id = 4)\n",
            "INFO:tensorflow:Training for 1 steps (1.00 epochs in total). Current step 0.\n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.77.70.18:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7014753024810212636)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2824378446078536440)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 18353421416525637319)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3613860360735023148)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7602228078820845081)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7692995491426394925)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 530778889258073656)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1252912477290865558)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 559447303619992242)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6364310534707199699)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17574968982001662718)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 16594522819542296226)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://benchmark-tpu-bucket/bert/models/askubuntu/2018-11-28 10:34:59/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 1 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 1.3831542, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 1 into gs://benchmark-tpu-bucket/bert/models/askubuntu/2018-11-28 10:34:59/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 1.3831542.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "INFO:tensorflow:Finished training up to step 1. Elapsed seconds 331.\n",
            "INFO:tensorflow:Starting to evaluate at step 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-28-09:41:12\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://benchmark-tpu-bucket/bert/models/askubuntu/2018-11-28 10:34:59/model.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (13) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (13) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Evaluation [13/13]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-28-09:42:11\n",
            "INFO:tensorflow:Saving dict for global step 1: eval_accuracy = 0.40384614, eval_loss = 1.4006776, global_step = 1, loss = 1.4898856\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: gs://benchmark-tpu-bucket/bert/models/askubuntu/2018-11-28 10:34:59/model.ckpt-1\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "INFO:tensorflow:Eval results at step 1: {'eval_accuracy': 0.40384614, 'eval_loss': 1.4006776, 'loss': 1.4898856, 'global_step': 1}\n",
            "INFO:tensorflow:Finished training up to step 1. Elapsed seconds 408.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAbRS9Nv-KeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Eval loop"
      ]
    },
    {
      "metadata": {
        "id": "vNPC8PUa-Jp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# forced to restart TPU each epoch since TPU's do not provide summary statistics\n",
        "if hparams.do_train_eval:\n",
        "  train_eval(hparams, estimator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEBbnGyMZo2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from typing import List, Iterable\n",
        "\n",
        "def predict(hparams: HParams) -> List[str]:\n",
        "    from src.my_classifier import get_model_fn_and_estimator, file_based_input_fn_builder\n",
        "    from src.run_classifier import file_based_convert_examples_to_features\n",
        "    import os\n",
        "    import numpy as np\n",
        "    from src.utils import convert_result_pred, get_rounded_f1\n",
        "\n",
        "    data_filename = hparams.data_dir / (hparams.task_name + '.tsv')\n",
        "    params = hparams._replace(use_tpu=False)  # BERT code warns against using TPU for predictions.\n",
        "    model_fn, estimator = get_model_fn_and_estimator(params)\n",
        "\n",
        "    predict_examples = get_examples(data_filename, SetType.test)\n",
        "    predict_file = os.path.join(params.output_dir, \"predict.tf_record\")\n",
        "    file_based_convert_examples_to_features(predict_examples, get_unique_intents(data_filename),\n",
        "                                            params.max_seq_length, get_tokenizer(params),\n",
        "                                            predict_file)\n",
        "\n",
        "    tf.logging.info(\"***** Running prediction*****\")\n",
        "    tf.logging.info(\"  Num examples = %d\", len(predict_examples))\n",
        "    tf.logging.info(\"  Batch size = %d\", params.predict_batch_size)\n",
        "\n",
        "    predict_drop_remainder = params.use_tpu\n",
        "    predict_input_fn = file_based_input_fn_builder(\n",
        "        input_file=predict_file,\n",
        "        seq_length=params.max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=predict_drop_remainder)\n",
        "\n",
        "    result: Iterable[np.ndarray] = estimator.predict(input_fn=predict_input_fn)\n",
        "    label_list = get_intents(data_filename)  # used for label_list[max_class] this might be wrong\n",
        "    y_pred = convert_result_pred(result, label_list)\n",
        "    print('f1 score: {}'.format(get_rounded_f1(params.data_dir / 'askubuntu.tsv', y_pred, average='micro')))\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2KMTc154HK7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train"
      ]
    },
    {
      "metadata": {
        "id": "V_gEMDtuqRlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.training import training_util\n",
        "from tensorflow.python.training.basic_session_run_hooks import SecondOrStepTimer\n",
        "from tensorflow.python.training.session_run_hook import SessionRunHook, SessionRunArgs\n",
        "\n",
        "class DevHook(SessionRunHook):\n",
        "    \"\"\"hook, based on ProfilerHook, to have the estimator output the run metadata into the model directory\n",
        "        source: https://stackoverflow.com/questions/45719176\"\"\"\n",
        "    def __init__(self,\n",
        "                 save_steps=None,\n",
        "                 save_secs=None,\n",
        "                 output_dir=\"\"):\n",
        "        self._output_tag = \"step-{}\"\n",
        "        self._output_dir = output_dir\n",
        "        self._timer = SecondOrStepTimer(\n",
        "            every_secs=save_secs, every_steps=save_steps)\n",
        "\n",
        "    def begin(self):\n",
        "        self._next_step = None\n",
        "        self._global_step_tensor = training_util.get_global_step()\n",
        "        tf.logging.info('creating file in: {}'.format(self._output_dir))\n",
        "        self._writer = tf.summary.FileWriter(self._output_dir + '/hook_data', \n",
        "                                             tf.get_default_graph())\n",
        "\n",
        "        if self._global_step_tensor is None:\n",
        "            raise RuntimeError(\"Global step should be created to use ProfilerHook.\")\n",
        "\n",
        "    def before_run(self, run_context):\n",
        "        tf.logging.info('before_run is called.')\n",
        "        self._request_summary = (\n",
        "                self._next_step is None or\n",
        "                self._timer.should_trigger_for_step(self._next_step)\n",
        "        )\n",
        "        requests = {\"global_step\": self._global_step_tensor}\n",
        "        opts = (tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
        "                if self._request_summary else None)\n",
        "        return SessionRunArgs(requests, options=opts)\n",
        "\n",
        "    def after_run(self, run_context, run_values):\n",
        "        # evaluate(params, estimator)\n",
        "        tf.logging.info('after_run is called.')\n",
        "        \n",
        "        stale_global_step = run_values.results[\"global_step\"]\n",
        "        global_step = stale_global_step + 1\n",
        "        if self._request_summary:\n",
        "            global_step = run_context.session.run(self._global_step_tensor)\n",
        "            self._writer.add_run_metadata(\n",
        "                run_values.run_metadata, self._output_tag.format(global_step))\n",
        "            self._writer.flush()\n",
        "        self._next_step = global_step + 1\n",
        "\n",
        "    def end(self, session):\n",
        "        self._writer.close()\n",
        "\n",
        "dev_hook = DevHook(save_steps=1, output_dir=hparams.output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_slxGYkRESsH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_start_time = datetime.now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rsP11oDJHMOn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if False:  # hparams.do_train:\n",
        "  train(hparams, estimator, dev_hook)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiHmFx-5Edvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "08f964ba-edba-4dad-a999-c72f5516c6d1"
      },
      "cell_type": "code",
      "source": [
        "duration = str(datetime.now() - training_start_time)\n",
        "print('Training took {}.'.format(duration))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 0:00:00.018211.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b9dx9rOJDQDA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ]
    },
    {
      "metadata": {
        "id": "FEu9ZpoHDRmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if hparams.do_eval:\n",
        "  evaluate(hparams, estimator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X2T6wMZ0hqbe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ]
    },
    {
      "metadata": {
        "id": "U5uxLmtwhlbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# note that predictions are non-deterministic\n",
        "if hparams.do_predict:\n",
        "  predict(hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}